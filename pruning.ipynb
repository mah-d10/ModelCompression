{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import StudentModel, BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import accuracy_fn, print_time\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "my_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "PRUNE_PERCENT = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10(\n",
    "    root=\"data\", train=True, download=True, transform=ToTensor()\n",
    ")\n",
    "\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\", train=False, download=True, transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StudentModel(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (log_softmax): LogSoftmax(dim=1)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = StudentModel().to(device=my_device)\n",
    "f = \"models/best_student_model_0.7_2.0_78.90.pt\"\n",
    "loaded_model.load_state_dict(torch.load(f, weights_only=True))\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = BaseModel().to(device=my_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.647316\n",
      "\n",
      "Test Accuracy of airplane: 84% (840/1000)\n",
      "Test Accuracy of automobile: 89% (891/1000)\n",
      "Test Accuracy of  bird: 69% (697/1000)\n",
      "Test Accuracy of   cat: 59% (590/1000)\n",
      "Test Accuracy of  deer: 76% (765/1000)\n",
      "Test Accuracy of   dog: 70% (704/1000)\n",
      "Test Accuracy of  frog: 84% (842/1000)\n",
      "Test Accuracy of horse: 83% (833/1000)\n",
      "Test Accuracy of  ship: 87% (879/1000)\n",
      "Test Accuracy of truck: 84% (848/1000)\n",
      "\n",
      "Test Accuracy (Overall): 78.89% (7889/10000)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "class_correct = np.zeros(10)\n",
    "class_total = np.zeros(10)\n",
    "\n",
    "loaded_model.eval()\n",
    "for X, y in test_dataloader:\n",
    "    X, y = X.to(my_device), y.to(my_device)\n",
    "    with torch.inference_mode():\n",
    "        output = loaded_model(X)\n",
    "    loss = criterion(output, y)\n",
    "    test_loss += loss.item() * X.size(0)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    correct_tensor = pred.eq(y.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    for i, _ in enumerate(correct):\n",
    "        label = int(y.data[i])\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "test_loss = test_loss / len(test_dataloader.dataset)\n",
    "print(\"Test Loss: {:.6f}\\n\".format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print(\n",
    "            \"Test Accuracy of %5s: %2d%% (%2d/%2d)\"\n",
    "            % (\n",
    "                class_names[i],\n",
    "                100 * class_correct[i] / class_total[i],\n",
    "                class_correct[i],\n",
    "                class_total[i],\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        print(\"Test Accuracy of %5s: N/A (no training examples)\" % (class_names[i]))\n",
    "\n",
    "correct = np.sum(class_correct, dtype=int)\n",
    "total = np.sum(class_total, dtype=int)\n",
    "print(f\"\\nTest Accuracy (Overall): {100.0 * correct / total}% ({correct}/{total})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(tensor: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    calculate the sparsity of the given tensor\n",
    "        sparsity = #zeros / #elements = 1 - #nonzeros / #elements\n",
    "    \"\"\"\n",
    "    return 1 - float(tensor.count_nonzero()) / tensor.numel()\n",
    "\n",
    "\n",
    "def get_model_sparsity(model: nn.Module) -> float:\n",
    "    \"\"\"\n",
    "    calculate the sparsity of the given model\n",
    "        sparsity = #zeros / #elements = 1 - #nonzeros / #elements\n",
    "    \"\"\"\n",
    "    num_nonzeros, num_elements = 0, 0\n",
    "    for param in model.parameters():\n",
    "        num_nonzeros += param.count_nonzero()\n",
    "        num_elements += param.numel()\n",
    "    return 1 - float(num_nonzeros) / num_elements\n",
    "\n",
    "\n",
    "def get_num_parameters(model: nn.Module, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the total number of parameters of model\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    num_counted_elements = 0\n",
    "    for param in model.parameters():\n",
    "        if count_nonzero_only:\n",
    "            num_counted_elements += param.count_nonzero()\n",
    "        else:\n",
    "            num_counted_elements += param.numel()\n",
    "    return num_counted_elements\n",
    "\n",
    "\n",
    "def get_model_size(model: nn.Module, data_width=32, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the model size in bits\n",
    "    :param data_width: #bits per element\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    return get_num_parameters(model, count_nonzero_only) * data_width\n",
    "\n",
    "\n",
    "Byte = 8\n",
    "KiB = 1024 * Byte\n",
    "MiB = 1024 * KiB\n",
    "GiB = 1024 * MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_grained_prune(tensor: torch.Tensor, sparsity: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    magnitude-based pruning for single tensor\n",
    "    :param tensor: torch.(cuda.)Tensor, weight of conv/fc layer\n",
    "    :param sparsity: float, pruning sparsity\n",
    "        sparsity = #zeros / #elements = 1 - #nonzeros / #elements\n",
    "    :return:\n",
    "        torch.(cuda.)Tensor, mask for zeros\n",
    "    \"\"\"\n",
    "    sparsity = min(max(0.0, sparsity), 1.0)\n",
    "    if sparsity == 1.0:\n",
    "        tensor.zero_()\n",
    "        return torch.zeros_like(tensor)\n",
    "    elif sparsity == 0.0:\n",
    "        return torch.ones_like(tensor)\n",
    "\n",
    "    num_elements = tensor.numel()\n",
    "\n",
    "    num_zeros = round(num_elements * sparsity)\n",
    "    importance = tensor.abs()\n",
    "    threshold = importance.view(-1).kthvalue(num_zeros).values\n",
    "    mask = torch.gt(importance, threshold)\n",
    "    tensor.mul_(mask)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineGrainedPruner:\n",
    "    def __init__(self, model, sparsity_dict):\n",
    "        self.masks = FineGrainedPruner.prune(model, sparsity_dict)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def apply(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if name in self.masks:\n",
    "                param *= self.masks[name]\n",
    "\n",
    "    @staticmethod\n",
    "    @torch.no_grad()\n",
    "    def prune(model, sparsity_dict):\n",
    "        masks = dict()\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.dim() > 1:  # we only prune conv and fc weights\n",
    "                if isinstance(sparsity_dict, dict):\n",
    "                    masks[name] = fine_grained_prune(param, sparsity_dict[name])\n",
    "                else:\n",
    "                    assert sparsity_dict < 1 and sparsity_dict >= 0\n",
    "                    if sparsity_dict > 0:\n",
    "                        masks[name] = fine_grained_prune(param, sparsity_dict)\n",
    "        return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "optimizer = torch.optim.Adam(loaded_model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "# scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_acc = 0\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "lr_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0% sparse model has size=0.15 MiB, which is 3.98X smaller than the 0.60 MiB dense model\n"
     ]
    }
   ],
   "source": [
    "dense_model_size = get_model_size(loaded_model)\n",
    "pruner = FineGrainedPruner(loaded_model, PRUNE_PERCENT)\n",
    "pruner.apply(loaded_model)\n",
    "sparse_model_size = get_model_size(loaded_model, count_nonzero_only=True)\n",
    "print(\n",
    "    f\"{PRUNE_PERCENT*100}% sparse model has size={sparse_model_size/MiB:.2f} MiB, \"\n",
    "    f\"which is {dense_model_size/sparse_model_size:.2f}X smaller than \"\n",
    "    f\"the {dense_model_size/MiB:.2f} MiB dense model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.3879 | test_acc: 17.64%\n",
      "\n",
      "Inference time on cuda: 0.738 seconds\n"
     ]
    }
   ],
   "source": [
    "loaded_model.eval()\n",
    "test_loss, test_acc = 0, 0\n",
    "time_start = timer()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for X, y in test_dataloader:\n",
    "        X, y = X.to(my_device), y.to(my_device)\n",
    "        y_pred = loaded_model.forward(X)\n",
    "        mean_batch_loss: torch.Tensor = criterion(y_pred, y)\n",
    "        test_loss += mean_batch_loss.item()\n",
    "        test_acc += accuracy_fn(y, torch.argmax(y_pred, dim=1))\n",
    "\n",
    "test_loss /= len(test_dataloader)\n",
    "test_acc /= len(test_dataloader)\n",
    "\n",
    "print(f\"test loss: {test_loss:.4f} | test_acc: {test_acc:.2f}%\")\n",
    "\n",
    "time_end = timer()\n",
    "total_train_time = print_time(\"Inference\", time_start, time_end, my_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train loss: 0.7344 | train_acc: 74.35%\n",
      "test loss: 1.7939 | test_acc: 36.11%\n",
      "\n",
      "epoch: 1\n",
      "train loss: 0.7053 | train_acc: 75.23%\n",
      "test loss: 1.3662 | test_acc: 51.54%\n",
      "\n",
      "epoch: 2\n",
      "train loss: 0.6726 | train_acc: 76.41%\n",
      "test loss: 1.2125 | test_acc: 57.55%\n",
      "\n",
      "epoch: 3\n",
      "train loss: 0.6546 | train_acc: 77.03%\n",
      "test loss: 1.1361 | test_acc: 60.28%\n",
      "\n",
      "epoch: 4\n",
      "train loss: 0.6346 | train_acc: 77.65%\n",
      "test loss: 1.0176 | test_acc: 64.62%\n",
      "\n",
      "epoch: 5\n",
      "train loss: 0.6230 | train_acc: 77.98%\n",
      "test loss: 0.9499 | test_acc: 66.89%\n",
      "\n",
      "epoch: 6\n",
      "train loss: 0.6106 | train_acc: 78.64%\n",
      "test loss: 0.9368 | test_acc: 67.12%\n",
      "\n",
      "epoch: 7\n",
      "train loss: 0.5966 | train_acc: 79.10%\n",
      "test loss: 0.9440 | test_acc: 66.59%\n",
      "\n",
      "epoch: 8\n",
      "train loss: 0.5830 | train_acc: 79.43%\n",
      "test loss: 0.9285 | test_acc: 67.25%\n",
      "\n",
      "epoch: 9\n",
      "train loss: 0.5655 | train_acc: 80.14%\n",
      "test loss: 0.8685 | test_acc: 69.37%\n",
      "\n",
      "epoch: 10\n",
      "train loss: 0.5536 | train_acc: 80.67%\n",
      "test loss: 0.8340 | test_acc: 71.03%\n",
      "\n",
      "epoch: 11\n",
      "train loss: 0.5372 | train_acc: 81.12%\n",
      "test loss: 0.8453 | test_acc: 70.49%\n",
      "\n",
      "epoch: 12\n",
      "train loss: 0.5219 | train_acc: 81.90%\n",
      "test loss: 0.8210 | test_acc: 71.63%\n",
      "\n",
      "epoch: 13\n",
      "train loss: 0.5091 | train_acc: 82.09%\n",
      "test loss: 0.7865 | test_acc: 72.79%\n",
      "\n",
      "epoch: 14\n",
      "train loss: 0.4901 | train_acc: 82.75%\n",
      "test loss: 0.7721 | test_acc: 73.22%\n",
      "\n",
      "epoch: 15\n",
      "train loss: 0.4733 | train_acc: 83.37%\n",
      "test loss: 0.7532 | test_acc: 74.08%\n",
      "\n",
      "epoch: 16\n",
      "train loss: 0.4575 | train_acc: 83.92%\n",
      "test loss: 0.7476 | test_acc: 74.52%\n",
      "\n",
      "epoch: 17\n",
      "train loss: 0.4405 | train_acc: 84.66%\n",
      "test loss: 0.7377 | test_acc: 75.10%\n",
      "\n",
      "epoch: 18\n",
      "train loss: 0.4289 | train_acc: 85.09%\n",
      "test loss: 0.7235 | test_acc: 75.51%\n",
      "\n",
      "epoch: 19\n",
      "train loss: 0.4205 | train_acc: 85.25%\n",
      "test loss: 0.7155 | test_acc: 75.79%\n",
      "\n",
      "epoch: 20\n",
      "train loss: 0.4103 | train_acc: 85.75%\n",
      "test loss: 0.7057 | test_acc: 76.14%\n",
      "\n",
      "epoch: 21\n",
      "train loss: 0.4041 | train_acc: 86.07%\n",
      "test loss: 0.7019 | test_acc: 76.36%\n",
      "\n",
      "epoch: 22\n",
      "train loss: 0.3992 | train_acc: 86.19%\n",
      "test loss: 0.6952 | test_acc: 76.79%\n",
      "\n",
      "epoch: 23\n",
      "train loss: 0.3940 | train_acc: 86.50%\n",
      "test loss: 0.6917 | test_acc: 76.89%\n",
      "\n",
      "epoch: 24\n",
      "train loss: 0.3961 | train_acc: 86.52%\n",
      "test loss: 0.6901 | test_acc: 76.90%\n",
      "\n",
      "Best test accuracy:  76.89696485623003\n",
      "\n",
      "Train time on cuda: 180.669 seconds\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(\"epoch:\", epoch)\n",
    "    loaded_model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for X, y in train_dataloader:\n",
    "        X, y = X.to(my_device), y.to(my_device)\n",
    "        y_pred = loaded_model.forward(X)\n",
    "        mean_batch_loss = criterion(y_pred, y)\n",
    "        train_loss += mean_batch_loss.item()\n",
    "        train_acc += accuracy_fn(y, torch.argmax(y_pred, dim=1))\n",
    "        optimizer.zero_grad()\n",
    "        mean_batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    pruner.apply(loaded_model)\n",
    "\n",
    "    train_loss /= len(train_dataloader)  # loss per batch\n",
    "    train_acc /= len(train_dataloader)  # accuracy per batch\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    lr_list.append(optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "    print(f\"train loss: {train_loss:.4f} | train_acc: {train_acc:.2f}%\")\n",
    "\n",
    "    loaded_model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(my_device), y.to(my_device)\n",
    "            y_pred = loaded_model.forward(X)\n",
    "            mean_batch_loss: torch.Tensor = criterion(y_pred, y)\n",
    "            test_loss += mean_batch_loss.item()\n",
    "            test_acc += accuracy_fn(y, torch.argmax(y_pred, dim=1))\n",
    "\n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc /= len(test_dataloader)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(\n",
    "            loaded_model.state_dict(), f\"models/best_pruned_model_{PRUNE_PERCENT}.pt\"\n",
    "        )\n",
    "\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    print(f\"test loss: {test_loss:.4f} | test_acc: {test_acc:.2f}%\")\n",
    "    print()\n",
    "\n",
    "train_time_end = timer()\n",
    "print(\"Best test accuracy: \", best_test_acc)\n",
    "total_train_time = print_time(\"Train\", time_start, train_time_end, my_device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
